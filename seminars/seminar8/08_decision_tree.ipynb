{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Семинар решающие деревья\n",
        "\n"
      ],
      "metadata": {
        "id": "khtV9YqTk7Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "260JqDjbCLEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df = pd.read_csv(\"/content/Titanic-Dataset.csv\")"
      ],
      "metadata": {
        "id": "Y-NaHRw8Jqiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df"
      ],
      "metadata": {
        "id": "dK2o2t-IJsPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titanic_df['Sex'] = titanic_df['Sex'].map({'male': 0, 'female': 1})"
      ],
      "metadata": {
        "id": "q7jIBGkjPTqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Базовое обучение DecisionTreeCLassifier"
      ],
      "metadata": {
        "id": "76WGBK7bFYAE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_df[[\"Age\", \"Sex\"]]\n",
        "y = titanic_df.Survived"
      ],
      "metadata": {
        "id": "e5Xr3S4SHSAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "9owAoPsB-bjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DecisionTreeClassifier реализует функционал построения дерева решений\n",
        "\n",
        "**criterion**: Функция, используемая для измерения качества разбиения. Поддерживаемые значения: \"gini\" для критерия Джини и \"entropy\" для энтропии.\n",
        "\n",
        "**max_depth**: Максимальная глубина дерева\n",
        "\n",
        "**min_samples_split**: Минимальное количество примеров, необходимое для выполнения разбиения узла\n",
        "\n",
        "**min_samples_leaf**: Минимальное количество примеров, необходимое для того, чтобы узел стал листом. Помогает контролировать глубину дерева."
      ],
      "metadata": {
        "id": "boqX_0cOP0vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим простой классификатор и ограничим его глубиной 2"
      ],
      "metadata": {
        "id": "dxmIt6WGJPfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_titanic_depth_2 = DecisionTreeClassifier(random_state=42, max_depth=2)#, criterion=\"entropy\")\n",
        "clf_titanic_depth_2.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "nRVkzb-p-dvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация дерева с глубиной 2\n",
        "plt.figure(figsize=(20,4))\n",
        "plot_tree(clf_titanic_depth_2, filled=True, feature_names=[\"Age\", \"Sex\"], class_names=[\"Not survived\", \"Survived\"])\n",
        "plt.title(\"Decision Tree with Depth 2\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fzDnoCPC-lQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Предскажем выживаемость пассажира\n",
        "new_passenger = {\n",
        "    'Age': 25.0,  # Возраст пассажира\n",
        "    'Sex': 1,     # 1 - женщина, 0 - мужчина\n",
        "}\n",
        "\n",
        "new_passenger_df = pd.DataFrame([new_passenger])\n",
        "clf_titanic_depth_2.predict(new_passenger_df)"
      ],
      "metadata": {
        "id": "JthkCPwGqltc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_titanic_no_depth = DecisionTreeClassifier(random_state=42)\n",
        "clf_titanic_no_depth.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "68EJk8XnJZdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация дерева без ограничения глубины дерева\n",
        "plt.figure(figsize=(40,10))\n",
        "plot_tree(clf_titanic_no_depth, filled=True, feature_names=[\"Age\", \"Sex\"], class_names=[\"Not survived\", \"Survived\"])\n",
        "plt.title(\"Decision Tree without depth limit\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Xc4R3p0UJb3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def titanic_metrics_calculation(y_test, y_pred):\n",
        "  print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "  print(f\"Precision: {precision_score(y_test, y_pred):.4f}\")\n",
        "  print(f\"Recall: {recall_score(y_test, y_pred):.4f}\")\n",
        "  print(f\"F1 Score: {f1_score(y_test, y_pred):.4f}\")"
      ],
      "metadata": {
        "id": "2vNjOHcwWOph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_depth_2 = clf_titanic_depth_2.predict(X_test)\n",
        "y_pred_no_depth = clf_titanic_no_depth.predict(X_test)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"Metrics for classification with depth 2:\")\n",
        "titanic_metrics_calculation(y_test, y_pred_depth_2)\n",
        "\n",
        "print(\"\\nMetrics for classification with no depth:\")\n",
        "titanic_metrics_calculation(y_test, y_pred_no_depth)"
      ],
      "metadata": {
        "id": "uBA6Dr8JpBXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Добавим еще один признак в анализ: класс каюты Pclass"
      ],
      "metadata": {
        "id": "mfqEsgmRRgaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = titanic_df[[\"Age\", \"Sex\", \"Pclass\"]]\n",
        "y = titanic_df.Survived"
      ],
      "metadata": {
        "id": "-qOZwVL0RlHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "pPaK1GrWRpZb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_titanic_3features = DecisionTreeClassifier(random_state=42, max_depth=10, min_samples_split=4, criterion=\"entropy\")\n",
        "clf_titanic_3features.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "oP0_x0WgRqeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация дерева\n",
        "plt.figure(figsize=(40,10))\n",
        "plot_tree(clf_titanic_3features, filled=True, feature_names=[\"Age\", \"Sex\", \"Pclass\"], class_names=[\"Not survived\", \"Survived\"])\n",
        "plt.title(\"Decision Tree with Entropy Criterion\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j3q3dbDuSCkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_3features = clf_titanic_3features.predict(X_test)\n",
        "\n",
        "print(\"\\nMetrics for Entropy Criterion:\")\n",
        "titanic_metrics_calculation(y_test, y_pred_3features)"
      ],
      "metadata": {
        "id": "5K_S780QSYMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавляем нового пассажира\n",
        "new_passenger = {\n",
        "    'Age': 25.0,  # Возраст пассажира\n",
        "    'Sex': 0,     # 1 - женщина, 0 - мужчина\n",
        "    'Pclass': 1,  # уровень каюты\n",
        "}\n",
        "\n",
        "new_passenger_df = pd.DataFrame([new_passenger])\n",
        "clf_titanic_3features.predict(new_passenger_df)"
      ],
      "metadata": {
        "id": "uyrdlophQkri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Интерпретируемость признаков"
      ],
      "metadata": {
        "id": "X5-Ru4yYZJDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем определить важность признаков, которые мы используем.\n",
        "DecisionTreeClassifier в scikit-learn позволяет считать эту важность по шагам:\n",
        "1.   **Инициализация:** для каждого признака устанавливается начальное значение важности, равное нулю\n",
        "2.   **Расчет уменьшения критерия:** Для каждого узла в дереве рассчитывается, насколько уменьшается критерий (например, критерий Джини или энтропия) после разбиения по данному признаку.\n",
        "Уменьшение неоднородности взвешивается по количеству образцов, которые проходят через данный узел. Это гарантирует, что разбиения, затрагивающие большее количество данных, имеют большее влияние на важность признака\n",
        "3. **Аккумуляция важности:** Уменьшение критерия для каждого признака суммируется по всем узлам, в которых этот признак использовался для разбиения\n",
        "4. **Нормализация:** Важности всех признаков нормализуются так, чтобы их сумма равнялась единице. Это позволяет легко сравнивать вклад каждого признака в общую модель"
      ],
      "metadata": {
        "id": "H50ihaiyaQha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature importance for Decision Tree with three features\n",
        "feature_importance = clf_titanic_3features.feature_importances_\n",
        "features = X.columns\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=feature_importance, y=features, orient='h')\n",
        "plt.title('Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.ylabel('Features')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IP5WW_UbZM17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Джини и энтропия\n"
      ],
      "metadata": {
        "id": "euFGlGU4FiP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Коэффициент Джини\n",
        "\n",
        "$$\n",
        "\\text{Gini}(X) = 1 - \\sum_{i=1}^{K} (p_i)^2\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $ K $ - количество классов.\n",
        "- $ p_i $ - вероятность класса $ i $ в X\n",
        "\n",
        "Коэффициент Джини варьируется от 0 (отсутствие неопределенности) до $ 1 - \\frac{1}{K} $(максимальная неопределенность). Меньшие значения указывают на лучшие разбиения, так как они предполают большую однородность в полученных узлах.\n",
        "\n",
        "### Энтропия\n",
        "\n",
        "$$\n",
        "\\text{Entropy}(X) = -\\sum_{i=1}^{K} p_i \\log_2(p_i)\n",
        "$$\n",
        "\n",
        "Где:\n",
        "- $ K $ - количество классов.\n",
        "- $ p_i $ - вероятность класса $ i $  в X\n",
        "\n",
        "Энтропия варьируется от 0 (отсутствие неопределенности) до $ \\log_2(K) $ (максимальная неопределенность).\n"
      ],
      "metadata": {
        "id": "Kk_df7ektNuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "np.random.seed(42)\n",
        "data_1 = pd.DataFrame({\n",
        "    'Feature1': np.random.randint(0, 200, size=200),\n",
        "    'Feature2': np.random.randint(0, 200, size=200),\n",
        "    'Class': np.concatenate([np.zeros(100), np.ones(100)])  # Majority class is 0\n",
        "})\n",
        "\n",
        "# Add noise to the features\n",
        "data_1['Feature1'] += np.random.normal(0, 10, size=200)\n",
        "data_1['Feature2'] += np.random.normal(0, 10, size=200)\n",
        "\n",
        "X_1 = data_1[['Feature1', 'Feature2']]\n",
        "y_1 = data_1['Class']\n",
        "\n",
        "# Split the data\n",
        "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train decision tree with Gini\n",
        "clf_gini_1 = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf_gini_1.fit(X_train_1, y_train_1)\n",
        "\n",
        "# Train decision tree with Entropy\n",
        "clf_entropy_1 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
        "clf_entropy_1.fit(X_train_1, y_train_1)\n",
        "\n",
        "# Accuracy comparison\n",
        "accuracy_gini_1 = accuracy_score(y_test_1, clf_gini_1.predict(X_test_1))\n",
        "accuracy_entropy_1 = accuracy_score(y_test_1, clf_entropy_1.predict(X_test_1))\n",
        "\n",
        "print(\"Dataset 1 - Gini Accuracy:\", accuracy_gini_1)\n",
        "print(\"Dataset 1 - Entropy Accuracy:\", accuracy_entropy_1)"
      ],
      "metadata": {
        "id": "8Ux6HVcjwzB1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Самостоятельно посчитаем джини и энтропию"
      ],
      "metadata": {
        "id": "N0S2YqHWs3Ln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создадим искусственный набор данных для удобства\n",
        "data = pd.DataFrame({\n",
        "    'Age': [22, 38, 26, 35, 28],\n",
        "    'Sex': [1, 0, 1, 0, 1],\n",
        "    'Pclass': [1, 1, 2, 3, 1],\n",
        "    'Survived': [0, 1, 1, 0, 1]\n",
        "})"
      ],
      "metadata": {
        "id": "9KNcn1Mgb3xA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет коэффициента Gini\n",
        "def gini_impurity(labels):\n",
        "    # TO DO\n",
        "    pass"
      ],
      "metadata": {
        "id": "OzPHY786iXRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Подсчет энтропии\n",
        "def entropy(labels):\n",
        "    # TO DO\n",
        "    pass"
      ],
      "metadata": {
        "id": "wcWXIyfqibz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_criterion(left_split, right_split):\n",
        "  gini_left = gini_impurity(left_split)\n",
        "  gini_right = gini_impurity(right_split)\n",
        "  entropy_left = entropy(left_split)\n",
        "  entropy_right = entropy(right_split)\n",
        "  print(f\"  Split at {value}: Gini Left = {gini_left:.4f}, Gini Right = {gini_right:.4f}, Entropy Left = {entropy_left:.4f}, Entropy Right = {entropy_right:.4f}\")\n",
        "  print(f\"gain = {gini_impurity(data['Survived']) - (len(left_split) / len(data['Survived'])) * gini_left - (len(right_split) / len(data['Survived'])) * gini_right}\")"
      ],
      "metadata": {
        "id": "z0qlbGMC4uxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate impurity for different splits\n",
        "print(\"Gini:\", gini_impurity(data[\"Survived\"]))\n",
        "print(\"Entropy:\", entropy(data[\"Survived\"]))\n",
        "for feature in ['Age', 'Sex', 'Pclass']:\n",
        "    print(f\"Feature: {feature}\")\n",
        "    if feature == 'Sex' or feature == 'Pclass':  # Categorical feature\n",
        "        for value in data[feature].unique():\n",
        "            left_split = data[data[feature] == value]['Survived']\n",
        "            right_split = data[data[feature] != value]['Survived']\n",
        "            count_criterion(left_split, right_split)\n",
        "    else:  # Numerical feature\n",
        "        for value in data[feature].unique():\n",
        "            left_split = data[data[feature] <= value]['Survived']\n",
        "            right_split = data[data[feature] > value]['Survived']\n",
        "            count_criterion(left_split, right_split)"
      ],
      "metadata": {
        "id": "YhQfQwJYs6Wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Задача регрессии"
      ],
      "metadata": {
        "id": "zKoH64X_7VZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grid(data):\n",
        "    x_min, x_max = data[:, 0].min() - 1, data[:, 0].max() + 1\n",
        "    y_min, y_max = data[:, 1].min() - 1, data[:, 1].max() + 1\n",
        "    return np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                         np.arange(y_min, y_max, 0.01))"
      ],
      "metadata": {
        "id": "62kgn0UTACi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "data_x = np.random.normal(size=(200, 2))\n",
        "data_y = np.sqrt(data_x[:, 0] ** 2 + data_x[:, 1] ** 2)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=60, cmap='winter')\n",
        "plt.title('Generated Data')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hgAv8tBKk3cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = DecisionTreeRegressor(random_state=42)\n",
        "clf.fit(data_x, data_y)\n",
        "\n",
        "xx, yy = get_grid(data_x)\n",
        "\n",
        "predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
        "plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=60, cmap='winter', edgecolor='k')"
      ],
      "metadata": {
        "id": "irLlzIWN_81Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим как будет выглядить разделение плоскости в зависимости от\n",
        "\n",
        "*   минимального количества объектов в листе\n",
        "*   максимальной глубины дерева"
      ],
      "metadata": {
        "id": "_5orDYIiAIqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 14))\n",
        "for i, max_depth in enumerate([2, 4, None]):\n",
        "    for j, min_samples_leaf in enumerate([15, 5, 1]):\n",
        "        clf = DecisionTreeRegressor(max_depth=max_depth, min_samples_leaf=min_samples_leaf)\n",
        "        clf.fit(data_x, data_y)\n",
        "        xx, yy = get_grid(data_x)\n",
        "        predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "        plt.subplot2grid((3, 3), (i, j))\n",
        "        plt.pcolormesh(xx, yy, predicted, cmap='winter')\n",
        "        plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='winter', edgecolor='k')\n",
        "        plt.title('max_depth=' + str(max_depth) + ' | min_samples_leaf=' + str(min_samples_leaf))"
      ],
      "metadata": {
        "id": "E2pQMqdH7Y7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Увеличение максимальной глубины и/или уменьшение минимального количества объектов выборки в листе приводит к увеличению качества на обучающей выборке и переобучению."
      ],
      "metadata": {
        "id": "Gg1ONEvOATgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Неустойчивость решающих деревьев"
      ],
      "metadata": {
        "id": "lNGw7v2QAdl_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Решающие деревья — это алгоритмы, чувствительные к изменениям в обучающей выборке. Даже незначительные изменения в данных могут существенно повлиять на структуру итогового классификатора. Давайте рассмотрим, как структура дерева изменяется при обучении на различных 90%-х подвыборках данных."
      ],
      "metadata": {
        "id": "Arj7X8RoAkRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(3):\n",
        "    clf = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "    indecies = np.random.randint(data_x.shape[0], size=int(data_x.shape[0] * 0.9))\n",
        "    clf.fit(data_x[indecies], data_y[indecies])\n",
        "    xx, yy = get_grid(data_x)\n",
        "    predicted = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "\n",
        "    plt.subplot2grid((1, 3), (0, i))\n",
        "    plt.pcolormesh(xx, yy, predicted, cmap='inferno')\n",
        "    plt.scatter(data_x[:, 0], data_x[:, 1], c=data_y, s=30, cmap='inferno', edgecolor='k')"
      ],
      "metadata": {
        "id": "yA1JmvP4AiDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Построение разбиения своими руками"
      ],
      "metadata": {
        "id": "h33ULK0OA_Ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создаем небольшой датасет с 3 признаками для задачи регрессии\n",
        "data = pd.DataFrame({\n",
        "    'Feature1': [1, 2, 3, 4, 5, 6],\n",
        "    'Feature2': [6, 5, 4, 3, 2, 1],\n",
        "    'Feature3': [1, 1, 2, 2, 3, 3],\n",
        "    'Target': [5.5, 5.0, 4.5, 4.0, 3.5, 3.0]\n",
        "})"
      ],
      "metadata": {
        "id": "nnnTa7mX8-gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для вычисления среднеквадратичной ошибки (MSE)\n",
        "def mean_squared_error(y_true, y_pred):\n",
        "    # TO DO\n",
        "    pass\n",
        "\n",
        "# Функция для вычисления уменьшения ошибки после разбиения\n",
        "def reduction_in_error(left_targets, right_targets, current_mse):\n",
        "    # TO DO\n",
        "    pass"
      ],
      "metadata": {
        "id": "BYIMl76_5ibA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для выбора лучшего разбиения\n",
        "def best_split_regression(data, feature):\n",
        "    # TO DO\n",
        "    X = data[feature].values\n",
        "    y = data['Target'].values\n",
        "\n",
        "    # Сортируем значения признака и соответствующие метки\n",
        "    # TO DO\n",
        "\n",
        "    # Ищем лучшее разбиение\n",
        "    # TO DO\n",
        "    pass"
      ],
      "metadata": {
        "id": "X_NIrA-G5v2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Проход по всем признакам и выбор лучшего разбиения\n",
        "features = ['Feature1', 'Feature2', 'Feature3']\n",
        "best_feature = None\n",
        "best_threshold = None\n",
        "best_reduction = 0\n",
        "\n",
        "for feature in features:\n",
        "    threshold, reduction = best_split_regression(data, feature)\n",
        "    if reduction > best_reduction:\n",
        "        best_reduction = reduction\n",
        "        best_feature = feature\n",
        "        best_threshold = threshold\n",
        "\n",
        "print(f\"Лучший признак для разбиения: {best_feature}\")\n",
        "print(f\"Лучший порог: {best_threshold}\")\n",
        "print(f\"Уменьшение ошибки: {best_reduction}\")"
      ],
      "metadata": {
        "id": "oYfjYEBf5xMb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}