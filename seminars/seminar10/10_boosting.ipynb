{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost xgboost lightgbm --upgrade"
      ],
      "metadata": {
        "id": "bSLTlaXbRARi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Семинар градиентный бустинг\n",
        "\n"
      ],
      "metadata": {
        "id": "khtV9YqTk7Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ],
      "metadata": {
        "id": "mgx-qS0mQgvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "X = np.linspace(0,10,300).reshape(-1,1)\n",
        "y = np.sinc(X).ravel()"
      ],
      "metadata": {
        "id": "Y-NaHRw8Jqiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.title('Generated Regression Dataset')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WKrGrPPb2hXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Решим задачу решающим деревом глубины 3\n",
        "tree = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "tree.fit(X, y)\n",
        "\n",
        "y_pred_tree = tree.predict(X)"
      ],
      "metadata": {
        "id": "M8aVZeXtVis3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred_tree, color='red', label='Decision Tree Prediction', linewidth=2)\n",
        "plt.title('Prediction with a Single Decision Tree')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_ZaJQgDD2uWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавим второй шаг, посчитаем разницу между метками и получившимся предсказанием\n",
        "residuals = y - y_pred_tree\n",
        "\n",
        "# Построим дерево решений, которое будем предсказывать residuals\n",
        "tree_residual = DecisionTreeRegressor(max_depth=3, random_state=42)\n",
        "tree_residual.fit(X, residuals)\n",
        "\n",
        "y_pred_residual = tree_residual.predict(X)"
      ],
      "metadata": {
        "id": "TCjwXmZEHuu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Суммируем предсказания двух деревьев решений\n",
        "y_pred_boosted = y_pred_tree + y_pred_residual"
      ],
      "metadata": {
        "id": "G1qIGKo23eWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred_boosted, color='green', label='Boosted Prediction', linewidth=2)\n",
        "plt.title('Prediction with One Step of Gradient Boosting')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LJIDJt0k3Ykq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "gbr.fit(X, y)\n",
        "\n",
        "y_pred_gbr = gbr.predict(X)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X, y, color='blue', label='Data points')\n",
        "plt.plot(X, y_pred_gbr, color='yellow', label='Gradient Boosting Prediction', linewidth=3)\n",
        "plt.title('Prediction with Gradient Boosting')\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Target')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dodw3FnnWARq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_tree = mean_squared_error(y, y_pred_tree)\n",
        "mse_boosted = mean_squared_error(y, y_pred_boosted)\n",
        "mse_gbr = mean_squared_error(y, y_pred_gbr)\n",
        "\n",
        "mse_tree, mse_boosted, mse_gbr"
      ],
      "metadata": {
        "id": "w9DBpC6nWFYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Градиентный Бустинг\n",
        "\n",
        "Основная идея заключается в последовательном построении моделей, каждая из которых пытается исправить ошибки предыдущей:\n",
        "\n",
        "1. **Инициализация**:\n",
        "   - Начинаем с базовой модели $F_0(x)$, которая делает начальные предсказания.\n",
        "\n",
        "2. **Вычисление Остатков**:\n",
        "   - Рассчитываем остатки $ r_i $ (разницу между фактическими значениями $ y_i $ и предсказаниями текущей модели $ F_m(x_i) $):\n",
        "   $$\n",
        "   r_i = y_i - F_m(x_i)\n",
        "   $$\n",
        "\n",
        "3. **Обучение Новой Модели**:\n",
        "   - Обучаем новую модель $ h_m(x) $ (обычно дерево решений) предсказывать эти остатки.\n",
        "\n",
        "4. **Обновление Предсказаний**:\n",
        "   - Обновляем предсказания, добавляя предсказания новой модели $ h_m(x) $ к предсказаниям предыдущей модели $ F_m(x) $:\n",
        "   $$\n",
        "   F_{m+1}(x) = F_m(x) + \\nu \\cdot h_m(x)\n",
        "   $$\n",
        "   где $ \\nu $ — коэффициент обучения (learning rate).\n",
        "\n",
        "5. **Повторение**:\n",
        "   - Повторяем шаги 2-4 заданное количество $ M $ раз или до тех пор, пока модель не достигнет нужного качества.\n",
        "\n",
        "6. **Финальная Модель**:\n",
        "   - Финальная модель представляет собой сумму всех обученных моделей:\n",
        "   $$\n",
        "   F_M(x) = F_0(x) + \\nu \\sum_{m=1}^{M} h_m(x)\n",
        "   $$"
      ],
      "metadata": {
        "id": "ZaORz3rhICi4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравним случайный лес с градиентным бустингом"
      ],
      "metadata": {
        "id": "YtiKxnWeKVA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Выберем разное количество деревьев для обучения\n",
        "n_trees_list = [10, 50, 100, 200, 300]\n",
        "mse_gbr_list = []\n",
        "mse_rf_list = []"
      ],
      "metadata": {
        "id": "Ym7-D8-18sJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n_trees in n_trees_list:\n",
        "    # Gradient Boosting\n",
        "    gbr = GradientBoostingRegressor(n_estimators=n_trees, max_depth=3, random_state=42)\n",
        "    gbr.fit(X, y)\n",
        "    y_pred_gbr = gbr.predict(X)\n",
        "    mse_gbr = mean_squared_error(y, y_pred_gbr)\n",
        "    mse_gbr_list.append(mse_gbr)\n",
        "\n",
        "    # Random Forest\n",
        "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=3, random_state=42)\n",
        "    rf.fit(X, y)\n",
        "    y_pred_rf = rf.predict(X)\n",
        "    mse_rf = mean_squared_error(y, y_pred_rf)\n",
        "    mse_rf_list.append(mse_rf)"
      ],
      "metadata": {
        "id": "x7KnyK0_MDLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(n_trees_list, mse_gbr_list, color='purple', label='Gradient Boosting MSE', marker='o')\n",
        "plt.plot(n_trees_list, mse_rf_list, color='green', label='Random Forest MSE', marker='s')\n",
        "plt.title('MSE vs Number of Trees')\n",
        "plt.xlabel('Number of Trees')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HIcBi8VB8t80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При небольшом числе деревьев алгоритм случайного леса работает лучше, чем градиентный бустинг. Все меняется с увеличением числа деревьев.\n"
      ],
      "metadata": {
        "id": "76WGBK7bFYAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Интерпретируемость признаков"
      ],
      "metadata": {
        "id": "X5-Ru4yYZJDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "1oxeANBc95Sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california = fetch_california_housing()\n",
        "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "y = california.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "PUricCZV97U8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gbr = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "gbr.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "aLSNxfZ--CRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = gbr.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "8CEKnmdS-FgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importances = gbr.feature_importances_\n",
        "features = X.columns"
      ],
      "metadata": {
        "id": "cwwuz-zQ-KyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance_df = pd.DataFrame({\n",
        "    'Feature': features,\n",
        "    'Importance': feature_importances\n",
        "}).sort_values(by='Importance', ascending=False)"
      ],
      "metadata": {
        "id": "vTNWLa6J-N7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(importance_df['Feature'], importance_df['Importance'], color='skyblue')\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.ylabel('Feature')\n",
        "plt.title('Feature Importances in Gradient Boosting')\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IP5WW_UbZM17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "KRdrZd1uQ5Sb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://xgboost.readthedocs.io/en/release_3.0.0/\n",
        "\n",
        "**Особенности**\n",
        "\n",
        "**Построение деревьев по уровням**\n",
        "\n",
        "Каждый уровень дерева заполняется полностью, прежде чем переходить к следующему уровню.\n",
        "\n",
        "**Параллельные вычисления**\n",
        "\n",
        "XGBoost поддерживает параллельные вычисления, что позволяет значительно ускорить процесс обучения. Особенно полезно при работе с большими наборами данных.\n",
        "\n",
        "**Много оптимизаций под капотом, которые ускоряют вычисления**"
      ],
      "metadata": {
        "id": "ywRG64GF-X5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [20, 10]\n",
        "\n",
        "california = fetch_california_housing()\n",
        "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "y = california.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучение модели XGBoost\n",
        "model = xgb.XGBRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Визуализация первого дерева\n",
        "xgb.plot_tree(model, num_trees=0)"
      ],
      "metadata": {
        "id": "JlZqqG4U7Gdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LightGBM"
      ],
      "metadata": {
        "id": "IvixoCJPRC3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://lightgbm.readthedocs.io/en/stable/\n",
        "\n",
        "**Особенности**\n",
        "\n",
        "**Построение деревьев по листьям**\n",
        "\n",
        "LightGBM использует стратегию роста по листьям. Это означает, что дерево растет, расширяя лист, который дает наибольший прирост информации. Такой подход может привести к асимметричным деревьям, но часто может достичь более высокой точности за меньшее время."
      ],
      "metadata": {
        "id": "ipe4VjqrmUeN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Создание LightGBM Dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "test_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
        "\n",
        "# Параметры модели\n",
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.1,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Обучение модели\n",
        "model = lgb.train(params, train_data, num_boost_round=100)\n",
        "\n",
        "# Визуализация первого дерева\n",
        "ax = lgb.plot_tree(model, tree_index=0, figsize=(20, 10), show_info=['split_gain', 'internal_value', 'internal_count', 'leaf_count'])"
      ],
      "metadata": {
        "id": "jW8RdhTb0OGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EFB (Exclusive Feature Bundling)**\n",
        "\n",
        "Алгоритм для улучшения эффективности обработки категориальных признаков объединяет некоторые признаки в группы, которые могут быть обработаны вместе. Это делается, чтобы снизить число вычислений.\n",
        "Категориальные признаки с большим количеством уникальных значений могут быть сложными для обработки, особенно когда у категориального признака есть много уникальных значений. Категориальные признаки группируются на основе их статистических свойств или распределений.\n",
        "\n",
        "**GOSS (Gradient-based One-Side Sampling)**\n",
        "\n",
        "Этот метод используется для ускорения обучения за счет выборки данных на основе градиентов. GOSS сохраняет экземпляры с большими градиентами и случайно выбирает экземпляры с малыми градиентами. Это позволяет сосредоточиться на наиболее информативных данных, ускоряя обучение без значительной потери точности"
      ],
      "metadata": {
        "id": "6dGGHg5m0NqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    'objective': 'regression',\n",
        "    'metric': 'mse',\n",
        "    'boosting_type': 'goss',  # Использование GOSS\n",
        "    'num_leaves': 31,\n",
        "    'learning_rate': 0.1,\n",
        "    'verbose': -1\n",
        "}\n",
        "\n",
        "# Обучение модели с GOSS\n",
        "model = lgb.train(params, train_data, num_boost_round=100)"
      ],
      "metadata": {
        "id": "GoSKuW5kCNoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CatBoost"
      ],
      "metadata": {
        "id": "xg-vXbZRP0Zy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://catboost.ai/\n",
        "\n",
        "**Особенности**\n",
        "\n",
        "**Симметричные деревья**\n",
        "\n",
        "CatBoost строит симметричные деревья: деревья имеют одинаковый предикат на каждом уровне.\n"
      ],
      "metadata": {
        "id": "OFnmoysIad65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostRegressor, Pool"
      ],
      "metadata": {
        "id": "gahQK_0Zrntl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california = fetch_california_housing()\n",
        "X = pd.DataFrame(california.data, columns=california.feature_names)\n",
        "y = california.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2dmLIbbBrHyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pool = Pool(X_train, y_train, feature_names=list(X.columns))\n",
        "\n",
        "model = CatBoostRegressor(\n",
        "    max_depth=2, verbose=False, max_ctr_complexity=1, iterations=2).fit(pool)\n",
        "\n",
        "model.plot_tree(\n",
        "    tree_idx=0,\n",
        "    pool=pool\n",
        ")"
      ],
      "metadata": {
        "id": "LYuN6NChqxLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Нативная поддержка категориальных признаков**\n",
        "\n",
        "CatBoost автоматически обрабатывает категориальные признаки, используя статистику на основе целевой переменной. Это позволяет модели эффективно работать с категориальными данными без необходимости предварительной обработки."
      ],
      "metadata": {
        "id": "wyLILP3Iq-sG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost.datasets import titanic\n",
        "titanic_df = titanic()\n",
        "\n",
        "X = titanic_df[0].drop('Survived',axis=1)\n",
        "y = titanic_df[0].Survived\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "lM-x37gVIMBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cat = (X.dtypes != float)\n",
        "for feature, feat_is_cat in is_cat.to_dict().items():\n",
        "    if feat_is_cat:\n",
        "        X[feature].fillna(\"NAN\", inplace=True)"
      ],
      "metadata": {
        "id": "g98WMW4trycZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cat"
      ],
      "metadata": {
        "id": "Sl8z_o2frzNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat_features_index = np.where(is_cat)[0]"
      ],
      "metadata": {
        "id": "U_DHJkyRsT12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pool = Pool(X, y, cat_features=cat_features_index, feature_names=list(X.columns))\n",
        "\n",
        "model = CatBoostRegressor(\n",
        "    max_depth=2, verbose=False, max_ctr_complexity=1, iterations=2).fit(pool)\n",
        "\n",
        "model.plot_tree(\n",
        "    tree_idx=0,\n",
        "    pool=pool\n",
        ")"
      ],
      "metadata": {
        "id": "0BUpepYGrr2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Динамический бустинг**\n",
        "\n",
        "Динамический бустинг — во время обучения делаются перестановки объектов для уменьшения переобучения"
      ],
      "metadata": {
        "id": "CTDPNm5Arq_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сравнение методов"
      ],
      "metadata": {
        "id": "WPVbWrX9RRsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from sklearn.datasets import fetch_california_housing, load_breast_cancer, load_digits\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from catboost import CatBoostRegressor, CatBoostClassifier"
      ],
      "metadata": {
        "id": "tvvzyzTRKSBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "california = fetch_california_housing()\n",
        "breast_cancer = load_breast_cancer()\n",
        "digits = load_digits()\n",
        "\n",
        "datasets = {\n",
        "    \"California Housing (Regression)\": (pd.DataFrame(california.data, columns=california.feature_names), pd.Series(california.target), \"regression\"),\n",
        "    \"Breast Cancer (Classification)\": (pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names), pd.Series(breast_cancer.target), \"classification\"),\n",
        "    \"Digits (Classification)\": (pd.DataFrame(digits.data, columns=[f'pixel_{i}' for i in range(digits.data.shape[1])]), pd.Series(digits.target), \"classification\")\n",
        "}"
      ],
      "metadata": {
        "id": "aH6TKjjmKadp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate models\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, task_type):\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    predict_time = time.time() - start_time\n",
        "\n",
        "    if task_type == \"regression\":\n",
        "        metric = mean_squared_error(y_test, y_pred)\n",
        "    else:\n",
        "        metric = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return metric, train_time, predict_time"
      ],
      "metadata": {
        "id": "4LkoIVcSKxb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare models on each dataset\n",
        "results = []\n",
        "\n",
        "for name, (X, y, task_type) in datasets.items():\n",
        "    print(f\"\\nНабор данных: {name}\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # XGBoost\n",
        "    if task_type == \"regression\":\n",
        "        xgboost_model = xgb.XGBRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "    else:\n",
        "        xgboost_model = xgb.XGBClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "    mse_xgb, train_time_xgb, predict_time_xgb = evaluate_model(xgboost_model, X_train, X_test, y_train, y_test, task_type)\n",
        "    print(f\"  XGBoost {'MSE' if task_type == 'regression' else 'Accuracy'}: {mse_xgb}, Train Time: {train_time_xgb:.2f}s, Predict Time: {predict_time_xgb:.2f}s\")\n",
        "\n",
        "    # LightGBM\n",
        "    if task_type == \"regression\":\n",
        "        lightgbm_model = lgb.LGBMRegressor(n_estimators=100, max_depth=3, verbosity=-1, random_state=42)\n",
        "    else:\n",
        "        lightgbm_model = lgb.LGBMClassifier(n_estimators=100, max_depth=3, verbosity=-1, random_state=42)\n",
        "    mse_lgb, train_time_lgb, predict_time_lgb = evaluate_model(lightgbm_model, X_train, X_test, y_train, y_test, task_type)\n",
        "    print(f\"  LightGBM {'MSE' if task_type == 'regression' else 'Accuracy'}: {mse_lgb}, Train Time: {train_time_lgb:.2f}s, Predict Time: {predict_time_lgb:.2f}s\")\n",
        "\n",
        "    # CatBoost\n",
        "    if task_type == \"regression\":\n",
        "        catboost_model = CatBoostRegressor(n_estimators=100, max_depth=3, random_state=42, verbose=0)\n",
        "    else:\n",
        "        catboost_model = CatBoostClassifier(n_estimators=100, max_depth=3, random_state=42, verbose=0)\n",
        "    mse_cb, train_time_cb, predict_time_cb = evaluate_model(catboost_model, X_train, X_test, y_train, y_test, task_type)\n",
        "    print(f\"  CatBoost {'MSE' if task_type == 'regression' else 'Accuracy'}: {mse_cb}, Train Time: {train_time_cb:.2f}s, Predict Time: {predict_time_cb:.2f}s\")\n",
        "\n",
        "    # GradientBoosting (scikit-learn)\n",
        "    if task_type == \"regression\":\n",
        "        sklearn_model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=42)\n",
        "    else:\n",
        "        sklearn_model = GradientBoostingClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
        "    mse_sk, train_time_sk, predict_time_sk = evaluate_model(sklearn_model, X_train, X_test, y_train, y_test, task_type)\n",
        "    print(f\"  GradientBoosting (sklearn) {'MSE' if task_type == 'regression' else 'Accuracy'}: {mse_sk}, Train Time: {train_time_sk:.2f}s, Predict Time: {predict_time_sk:.2f}s\")\n",
        "\n",
        "    results.append((name, \"XGBoost\", mse_xgb, train_time_xgb, predict_time_xgb))\n",
        "    results.append((name, \"LightGBM\", mse_lgb, train_time_lgb, predict_time_lgb))\n",
        "    results.append((name, \"CatBoost\", mse_cb, train_time_cb, predict_time_cb))\n",
        "    results.append((name, \"GradientBoosting (sklearn)\", mse_sk, train_time_sk, predict_time_sk))"
      ],
      "metadata": {
        "id": "M3hRDaf4mZP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results, columns=[\"Dataset\", \"Model\", \"Metric\", \"Train Time\", \"Predict Time\"])\n",
        "print(\"\\nСводная таблица результатов:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "id": "Yt3c9WfeK6nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Пример сравнения алгоритмов градиентного бустинга](https://arxiv.org/pdf/2305.17094)"
      ],
      "metadata": {
        "id": "0Vybme8-ZhhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Реализация бустинга самостоятельно"
      ],
      "metadata": {
        "id": "pS3z6-_fdM6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = california.data, california.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "LJTU-ab-Lr_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Число деревьев в бустинге\n",
        "n_trees = 100\n",
        "# Learning rate\n",
        "learning_rate = 0.3\n",
        "# Максимальная глубина деревьев\n",
        "max_depth = 3"
      ],
      "metadata": {
        "id": "iHmPPpcdnAAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = np.mean(y_train)"
      ],
      "metadata": {
        "id": "5-mMH6-hnBn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trees = []\n",
        "\n",
        "# Цикл обучения градиентного бустинга\n",
        "for i in range(n_trees):\n",
        "    # TO DO\n",
        "    # Calculate the residuals\n",
        "\n",
        "    # Train a decision tree on the residuals\n",
        "\n",
        "    # Update the prediction with the learning rate and the new tree's prediction\n",
        "\n",
        "    # Store the tree"
      ],
      "metadata": {
        "id": "fePzp6L3nDsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X):\n",
        "    # TO DO\n",
        "    # Start with the initial prediction\n",
        "\n",
        "    # Add the predictions of all trees\n",
        "\n",
        "    pass\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_test = predict(X_test)"
      ],
      "metadata": {
        "id": "1griKcK2nGRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse = mean_squared_error(y_test, y_pred_test)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "id": "oen5a4tsnH8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}